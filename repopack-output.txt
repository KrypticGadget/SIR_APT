This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-11-04T08:43:20.023Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.env.example
.github/workflows/main.yml
.gitignore
.streamlit/config.toml
app.py
dir.txt
README.md
requirements.txt
setup_mongodb.py
static/styles.css
utils/address_standardizer.py
utils/auth.py
utils/data_processor.py
utils/database.py

================================================================
Repository Files
================================================================

================
File: .env.example
================
# .env.example
MONGODB_URI=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/<database>?retryWrites=true&w=majority
JWT_SECRET_KEY=your_generated_jwt_secret_key_here
NOMINATIM_USER_AGENT=sothebys_international_realty_nyc

================
File: .github/workflows/main.yml
================
name: Deploy to Streamlit Cloud

on:
  push:
    branches: [ main ]
  pull_request:
    branc

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
ENV/

# Environment variables
.env
.env.local
.env.*.local

# IDE
.idea/
.vscode/
*.swp
*.swo

# Project specific
data/inputs/*
data/outputs/*
!data/inputs/.gitkeep
!data/outputs/.gitkeep

# Streamlit secrets
.streamlit/secrets.toml

# System files
.DS_Store
Thumbs.db

================
File: .streamlit/config.toml
================
[theme]
primaryColor = "#FFFFFF"
backgroundColor = "#002A5C"
secondaryBackgroundColor = "#001A3C"
textColor = "#FFFFFF"
font = "sans serif"

[server]
enableCORS = false
enableXsrfProtection = true

[browser]
gatherUsageStats = false

================
File: app.py
================
# app.py
import streamlit as st
import pandas as pd
import os
from datetime import datetime
from utils.data_processor import DataProcessor
from utils.auth import AuthHandler
import base64

def load_css(css_file):
    """Load CSS file"""
    try:
        with open(css_file) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except Exception as e:
        st.error(f"Error loading CSS file: {str(e)}")

# Initialize handlers
auth_handler = AuthHandler()

# Configure page
st.set_page_config(
    page_title="Sotheby's Address Validator",
    page_icon="./assets/sothebys-favicon.ico",
    layout="wide"
)

# Load CSS
load_css('static/styles.css')

# Helper functions
def safe_read_excel(file):
    """Safely read Excel file, handling empty files and other errors."""
    try:
        return pd.read_excel(file)
    except (pd.errors.EmptyDataError, ValueError):
        st.error("The uploaded file appears to be empty or invalid.")
        return None
    except Exception as e:
        st.error(f"Error reading file: {str(e)}")
        return None

def get_readable_timestamp():
    """Get current timestamp in readable format."""
    return datetime.now().strftime("%B %d, %Y at %I:%M %p")

def get_file_timestamp():
    """Get timestamp for file naming."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def load_image(image_path):
    try:
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return None

def display_logo(context='main'):
    """Display logo with context-specific styling"""
    logo_data = load_image('./assets/sothebys-logo.png')
    if logo_data:
        container_class = 'logo-container-login' if context == 'login' else 'logo-container-main'
        st.markdown(f"""
            <div class="{container_class}">
                <img src="data:image/png;base64,{logo_data}" />
            </div>
        """, unsafe_allow_html=True)

# Configure valid property classes
VALID_PROPERTY_CLASSES = ["CD", "B9", "B2", "B3", "CO", "B1", "C1", "A9", "C2"]
data_processor = DataProcessor(VALID_PROPERTY_CLASSES)

# Authentication check
if 'user_token' not in st.session_state:
    st.session_state.user_token = None

# Login Section Update
if not st.session_state.user_token:
    display_logo('login')
    st.markdown('<h1 class="standard-text">Login</h1>', unsafe_allow_html=True)
    
    # Center the login form
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        with st.form("login_form"):
            st.markdown("""
                <div class="login-container">
                    <h3 style='text-align: center; color: #002A5C; margin-bottom: 20px; font-weight: 500;'>
                        Use your @sothebys.realty email to login
                    </h3>
            """, unsafe_allow_html=True)
            
            email = st.text_input("Email", placeholder="example@sothebys.realty")
            password = st.text_input("Password", type="password")
            submitted = st.form_submit_button("Login")
            
            if submitted:
                if not email or not password:
                    st.error("Please enter both email and password")
                else:
                    if auth_handler.verify_email_domain(email):
                        st.info(f"Attempting login with email: {email}")
                        token = auth_handler.login(email, password)
                        if token:
                            st.session_state.user_token = token
                            st.experimental_rerun()
                        else:
                            st.error(f"Invalid credentials for {email}")
                    else:
                        st.error("Please use your Sotheby's International Realty email (@sothebys.realty)")
            st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

# Main application (only shown to authenticated users)
user = auth_handler.verify_token(st.session_state.user_token)
if not user:
    st.session_state.user_token = None
    st.experimental_rerun()

display_logo('main')

# Sidebar with user info and logout
with st.sidebar:
    st.markdown(f'<div class="user-welcome">Welcome, {user["name"]}</div>', unsafe_allow_html=True)
    
    if st.button("Logout"):
        st.session_state.user_token = None
        st.experimental_rerun()

# Navigation
if user.get('role') == 'admin':
    page = st.sidebar.radio("", ['Process New Data', 'View History', 'User Management'])
else:
    page = st.sidebar.radio("", ['Process New Data', 'View History'])

if page == 'Process New Data':
    st.markdown('<h1 class="standard-text">Property Address Validator</h1>', unsafe_allow_html=True)
    st.markdown('<h2 class="standard-text">Process Property Data</h2>', unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader("Upload Property Shark Data Export (Excel)", type="xlsx", key="property")
    if uploaded_file:
        input_data = safe_read_excel(uploaded_file)
        if input_data is None or input_data.empty:
            st.error("Unable to process the uploaded file. Please ensure it contains valid data.")
        else:
            try:
                file_timestamp = get_file_timestamp()
                readable_timestamp = get_readable_timestamp()
                original_filename = uploaded_file.name
                
                base_name = os.path.splitext(original_filename)[0]
                processed_filename = f"{base_name}_processed_{file_timestamp}.csv"
                
                processed_data = data_processor.process_file(uploaded_file)
                
                if processed_data is None or processed_data.empty:
                    st.error("No valid data was found after processing.")
                else:
                    os.makedirs("data/outputs", exist_ok=True)
                    output_path = os.path.join("data/outputs", processed_filename)
                    processed_data.to_csv(output_path, index=False)
                    
                    st.markdown('<div class="standard-text">Filtered and Standardized Address List</div>', unsafe_allow_html=True)
                    st.markdown('<div class="standard-text-dark">', unsafe_allow_html=True)
                    st.dataframe(processed_data[["Full Address", "Processed Date"]])
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    st.download_button(
                        label="Download Processed List",
                        data=processed_data.to_csv(index=False),
                        file_name=processed_filename,
                        mime="text/csv"
                    )
                    
                    st.success(f"File processed successfully! Saved as {processed_filename}")
                    
            except Exception as e:
                st.error(f"An error occurred while processing the file: {str(e)}")

elif page == 'View History':
    st.markdown('<h1 class="standard-text">Processing History</h1>', unsafe_allow_html=True)
    
    output_dir = "data/outputs"
    if os.path.exists(output_dir):
        processed_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
        
        if not processed_files:
            st.info("No processing history available yet.")
        else:
            processed_files.sort(key=lambda x: os.path.getmtime(os.path.join(output_dir, x)), reverse=True)
            
            st.markdown('<h2 class="standard-text">Processed Files</h2>', unsafe_allow_html=True)
            for filename in processed_files:
                file_path = os.path.join(output_dir, filename)
                mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                with st.expander(f"{filename} (Processed on {mod_time.strftime('%B %d, %Y at %I:%M %p')})"):
                    try:
                        df = pd.read_csv(file_path)
                        st.markdown('<div class="standard-text-dark">', unsafe_allow_html=True)
                        st.dataframe(df)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        with open(file_path, 'rb') as f:
                            st.download_button(
                                label=f"Download {filename}",
                                data=f,
                                file_name=filename,
                                mime="text/csv"
                            )
                    except Exception as e:
                        st.error(f"Error loading file: {str(e)}")
    else:
        st.info("No processing history available yet.")

elif page == 'User Management' and user.get('role') == 'admin':
    st.markdown('<h1 class="standard-text">User Management</h1>', unsafe_allow_html=True)
    
    with st.form("add_user_form", clear_on_submit=True):
        st.markdown('<h2 class="standard-text">Add New User</h2>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            new_email = st.text_input("Email (@sothebysrealty.com)")
            new_name = st.text_input("Full Name")
        with col2:
            new_password = st.text_input("Password", type="password")
            confirm_password = st.text_input("Confirm Password", type="password")
        
        submitted = st.form_submit_button("Add User")
        
        if submitted:
            if new_password != confirm_password:
                st.error("Passwords do not match!")
            elif not new_email or not new_name or not new_password:
                st.error("All fields are required!")
            else:
                try:
                    auth_handler.add_user(new_email, new_password, new_name, user['email'])
                    st.success(f"Successfully added user: {new_email}")
                except ValueError as e:
                    st.error(str(e))
                except Exception as e:
                    st.error(f"An error occurred: {str(e)}")
    
    st.markdown('<h2 class="standard-text">Current Users</h2>', unsafe_allow_html=True)
    users = auth_handler.get_all_users()
    
    if users:
        user_data = []
        for email, info in users.items():
            user_data.append({
                'Email': email,
                'Name': info['name'],
                'Role': info['role'].capitalize(),
                'Created On': info.get('created_at', 'N/A'),
                'Created By': info.get('created_by', 'N/A')
            })
        
        st.markdown('<div class="standard-text-dark">', unsafe_allow_html=True)
        user_df = pd.DataFrame(user_data)
        st.dataframe(user_df, hide_index=True)
        st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown('<h2 class="standard-text">Delete User</h2>', unsafe_allow_html=True)
        delete_email = st.selectbox(
            "Select user to delete",
            options=[email for email in users.keys() if email != user['email']],
            format_func=lambda x: f"{x} ({users[x]['name']})"
        )
        
        if st.button("Delete Selected User", type="secondary"):
            if delete_email:
                try:
                    auth_handler.delete_user(delete_email, user['email'])
                    st.success(f"Successfully deleted user: {delete_email}")
                    st.experimental_rerun()
                except Exception as e:
                    st.error(f"Error deleting user: {str(e)}")
    else:
        st.info("No users found in the system.")

================
File: dir.txt
================
real_estate_validator/
├── app.py
├── requirements.txt
├── vercel.json
├── .env.example
├── .gitignore
├── README.md
├── assets/
│   ├── favicon.ico
│   └── sothebys-logo.png
├── .streamlit/
│   └── config.toml
└── utils/
    ├── __init__.py
    ├── address_standardizer.py
    ├── auth.py
    ├── data_processor.py
    └── database.py

================
File: README.md
================
# SIR Prospect Address Validator

## TLDR - Critical Information
- **Live App URL**: [Streamlit-URL]
- **Admin Login**: 
  - Email: ****.*****@********.******
  - Password: **********
- **Key Features**: Upload Property Shark exports, standardize addresses, remove duplicates
- **Access**: Only @********.****** email domains
- **Support**: REDACTED
- **Security**: JWT authentication, role-based access, domain-restricted
- **Data**: All processed files stored in MongoDB with backup
- **Deployment**: Hosted on Vercel, MongoDB Atlas backend

## Quick Start
1. Login with Sotheby's email
2. Upload Property Shark Excel export
3. Get standardized address list
4. Download processed file
5. View processing history

A secure, enterprise-grade Streamlit application for processing and validating real estate property addresses, specifically designed for SIR.

## Features

### Core Functionality
- Upload and process Property Shark data exports
- Standardize property addresses
- Remove duplicate entries
- Track processing history
- View and download processed files

### Enterprise Features
- Secure authentication system
- Domain-restricted access (@********.******)
- User management interface
- Processing history tracking
- Role-based access control
- Professional branding


## Authentication

### Initial Admin Access
- Email: REDACTED
- Password: Contact administrator for credentials

### User Management
- Only administrators can add new users
- Domain restricted to @********.******
- Secure password policies enforced
- User activity tracking

## Usage

1. Login with Sotheby's credentials
2. Navigate using the sidebar menu:
   - Process New Data
   - View History
   - User Management (Admin only)

### Processing Data
1. Upload Property Shark Excel export
2. System will automatically:
   - Standardize addresses
   - Remove duplicates
   - Generate downloadable processed file

### Viewing History
- Access all previously processed files
- Download original or processed files
- View processing statistics

### User Management (Admin)
- Add new users
- View user list
- Manage user access
- Track user activity

## Development

### Technology Stack
- Python 3.9+
- Streamlit for web interface
- Pandas for data processing
- MongoDB for data storage
- JWT for authentication
- bcrypt for password hashing

### Styling
- Custom Sotheby's branding
- Professional UI/UX
- Responsive design
- Consistent color scheme (#002A5C)

## Security Features
- Domain-restricted access
- Secure password handling
- JWT token authentication
- Session management
- Role-based access control
- Secure file handling

## Deployment

The application is deployed on Vercel and can be accessed at:
[Your-Streamlit-URL]

### Production Configuration
1. Set up MongoDB Atlas cluster
2. Configure Vercel environment variables
3. Add Vercel's IP addresses to MongoDB network access

## Support

For support, please contact:
- Technical Issues: [Your Technical Contact]
- User Access: REDACTED

## License

Internal use only - SIR

## Setting up Nominatim User Agent

To use the Nominatim service for address normalization, you need to set up a user agent. This can be done by adding the following line to your environment variables:

```bash
NOMINATIM_USER_AGENT=your_unique_user_agent
```

Replace `your_unique_user_agent` with a unique identifier for your application. This is required by Nominatim to identify your requests.

================
File: requirements.txt
================
streamlit==1.29.0
pandas==2.1.3
openpyxl==3.1.2
numpy==1.26.2
pymongo==4.6.1
dnspython==2.4.2
python-dotenv==1.0.0
bcrypt==4.1.1
python-jose==3.3.0
PyJWT==2.8.0
watchdog==3.0.0
python-multipart==0.0.6
typing-extensions==4.7.1
geopy==2.2.0

================
File: setup_mongodb.py
================
"""
MongoDB setup and test script for Sotheby's Address Validator
"""

import os
from dotenv import load_dotenv
from pymongo import MongoClient, ASCENDING, DESCENDING
import gridfs
from datetime import datetime

# Load environment variables
load_dotenv()

def setup_mongodb():
    """Set up MongoDB connection and initialize collections"""
    try:
        # Get MongoDB URI from environment variables
        uri = os.getenv('MONGODB_URI')
        if not uri:
            raise ValueError("MONGODB_URI not found in environment variables")

        # Create MongoDB client
        client = MongoClient(uri)
        
        # Test connection with ping
        client.admin.command('ping')
        print("✅ Successfully connected to MongoDB!")

        # Get database
        db = client.sothebys_validator
        
        # Initialize GridFS
        fs = gridfs.GridFS(db)
        
        # Set up collections with indexes
        setup_collections(db)
        
        return client, db, fs
    
    except Exception as e:
        print(f"❌ Error setting up MongoDB: {str(e)}")
        return None, None, None

def setup_collections(db):
    """Set up collections and their indexes"""
    try:
        # Users collection
        if 'users' not in db.list_collection_names():
            users = db.create_collection('users')
            users.create_index([('email', ASCENDING)], unique=True)
            print("✅ Created users collection with email index")

        # Processing logs collection
        if 'processing_logs' not in db.list_collection_names():
            logs = db.create_collection('processing_logs')
            logs.create_index([('timestamp', DESCENDING)])
            logs.create_index([('user_email', ASCENDING)])
            print("✅ Created processing_logs collection with indexes")

        # Test inserting a processing log
        test_log = {
            'filename': 'test.xlsx',
            'user_email': 'test@sothebysrealty.com',
            'timestamp': datetime.now(),
            'status': 'success',
            'records_processed': 10,
            'records_filtered': 5
        }
        db.processing_logs.insert_one(test_log)
        print("✅ Successfully inserted test processing log")

        # Test GridFS
        fs = gridfs.GridFS(db)
        test_file_id = fs.put(
            b"Test data",
            filename="test.txt",
            metadata={'test': True}
        )
        fs.delete(test_file_id)
        print("✅ Successfully tested GridFS operations")

    except Exception as e:
        print(f"❌ Error setting up collections: {str(e)}")

def display_database_info(db):
    """Display information about the database and its collections"""
    try:
        print("\n📊 Database Information:")
        print("-" * 50)
        
        # List collections
        collections = db.list_collection_names()
        print(f"\nCollections in database:")
        for collection in collections:
            count = db[collection].count_documents({})
            print(f"- {collection}: {count} documents")

        # Display indexes for each collection
        print("\nIndexes:")
        for collection in collections:
            print(f"\n{collection} indexes:")
            indexes = db[collection].list_indexes()
            for index in indexes:
                print(f"- {index['name']}: {index['key']}")

    except Exception as e:
        print(f"❌ Error displaying database info: {str(e)}")

def main():
    """Main setup function"""
    print("\n🚀 Setting up MongoDB for Sotheby's Address Validator...\n")
    
    # Set up MongoDB connection and collections
    client, db, fs = setup_mongodb()
    
    # Check if setup was successful
    if client is not None and db is not None and fs is not None:
        # Display database information
        display_database_info(db)
        
        print("\n✨ MongoDB setup complete!")
        
        # Clean up
        client.close()
    else:
        print("\n❌ MongoDB setup failed")

if __name__ == "__main__":
    main()

================
File: static/styles.css
================
/* Main app styling and background */
.stApp {
    background-color: #002A5C;
    color: #FFFFFF;
    max-width: 1200px;
    margin: 0 auto;
}

.stApp > header {
    background-color: transparent;
}

/* Logo containers */
.logo-container-login, .logo-container-main {
    text-align: center;
    padding: 1rem 0;
    margin-bottom: 2rem;
    border-radius: 8px;
}

.logo-container-login {
    background-color: transparent;
}

.logo-container-main {
    background-color: #002A5C;
}

.logo-container-login img,
.logo-container-main img {
    max-width: 200px;
}

/* Typography */
h1, h2, h3, h4, h5, h6 {
    color: #FFFFFF !important;
    font-weight: 600 !important;
}

p, span, div {
    color: inherit;
}

/* Login specific styling */
.login-container {
    max-width: 400px;
    margin: 0 auto;
    padding: 2rem;
    background-color: #FFFFFF;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    color: #002A5C !important;
}

/* Login message styling */
.login-container h3,
#use-your-sothebys-realty-email-to-login {
    font-size: 0.9rem;
    margin: 0 0 1.5rem 0;
    color: #002A5C !important;
    text-align: center;
    font-weight: 500 !important;
    background: none !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
}

/* Remove box around login message */
div[data-testid="stForm"] > div:first-child {
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
    margin: 0 !important;
}

.login-container .stTextInput > label {
    color: #002A5C !important;
}

/* Form elements */
.stTextInput>div>div>input {
    border: 1px solid #002A5C !important;
    color: #002A5C !important;
    background-color: #FFFFFF;
    border-radius: 4px;
}

.stTextInput>div>div>input:focus {
    border: 2px solid #002A5C !important;
    box-shadow: none !important;
}

.stTextInput > label,
.stSelectbox > label,
.stFileUploader > label {
    color: #FFFFFF !important;
}

/* Buttons */
.stButton>button {
    background-color: #002A5C !important;
    color: #FFFFFF !important;
    border: 1px solid #FFFFFF !important;
    border-radius: 4px !important;
    padding: 0.5rem 1rem !important;
    font-weight: 500 !important;
    width: 100% !important;
    margin-top: 1rem !important;
}

.stButton>button:hover {
    background-color: #003A7C !important;
}

================
File: utils/address_standardizer.py
================
import re
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError

class AddressStandardizer:
    """Standardizes address fields with common abbreviations and typos."""

    def __init__(self):
        self.geolocator = Nominatim(user_agent="address_normalizer")

    def normalize_address(self, address):
        try:
            location = self.geolocator.geocode(address, addressdetails=True)
            if location:
                return location.address
            else:
                return None
        except (GeocoderTimedOut, GeocoderServiceError) as e:
            print(f"Geocoding error: {e}")
            return None

    def standardize(self, address):
        # Comprehensive list of abbreviations and common typos
        abbreviations = {
            "St": "Street", "Str": "Street", "Streeet": "Street", "Sreet": "Street", "St.": "Street",
            "Ave": "Avenue", "Aven": "Avenue", "Avenu": "Avenue", "Avnue": "Avenue", "Avenuee": "Avenue", "Av": "Avenue",
            "Blvd": "Boulevard", "Bld": "Boulevard", "Bulevard": "Boulevard", "Blv": "Boulevard", "Blvd.": "Boulevard",
            "Rd": "Road", "Roa": "Road", "Rode": "Road", "Rd.": "Road",
            "Dr": "Drive", "Drv": "Drive", "Dri": "Drive", "Drve": "Drive", "Dr.": "Drive",
            "Ln": "Lane", "La": "Lane", "Lne": "Lane", "Ln.": "Lane",
            "Pl": "Place", "Plc": "Place", "Pla": "Place", "Pl.": "Place",
            "Ct": "Court", "Crt": "Court", "Cr": "Court", "Court": "Court",
            "Sq": "Square", "Sqre": "Square", "Squr": "Square", "Sqr": "Square", "Square": "Square",
            "Pkwy": "Parkway", "Pkway": "Parkway", "Pky": "Parkway", "Pkw": "Parkway",
            "Cir": "Circle", "Crcle": "Circle", "Circ": "Circle", "Cir.": "Circle",
            "Terr": "Terrace", "Ter": "Terrace", "Tr": "Terrace",
            "Hwy": "Highway", "Hiway": "Highway", "Hyw": "Highway", "Hway": "Highway",
            "Expr": "Expressway", "Expw": "Expressway", "Exp": "Expressway",
            "Ctr": "Center", "Cntr": "Center", "Ctr.": "Center",
            "Mt": "Mountain", "Mtn": "Mountain", "Mntn": "Mountain",
            # Directional abbreviations
            "N": "North", "N.": "North", "No": "North", "No.": "North",
            "S": "South", "S.": "South", "So": "South", "So.": "South",
            "E": "East", "E.": "East",
            "W": "West", "W.": "West",
            "NE": "Northeast", "N.E.": "Northeast", "N.E": "Northeast", "NE.": "Northeast",
            "NW": "Northwest", "N.W.": "Northwest", "N.W": "Northwest", "NW.": "Northwest",
            "SE": "Southeast", "S.E.": "Southeast", "S.E": "Southeast", "SE.": "Southeast",
            "SW": "Southwest", "S.W.": "Southwest", "S.W": "Southwest", "SW.": "Southwest"
        }

        if not address:
            return address

        # Convert to string if not already
        address = str(address)

        # Replace abbreviations using regex with word boundaries
        for abbr, full in abbreviations.items():
            address = re.sub(rf'\b{abbr}\b', full, address, flags=re.IGNORECASE)

        # Remove double spaces
        address = re.sub(r'\s+', ' ', address)
        
        # Remove trailing/leading whitespace
        address = address.strip()

        # Normalize address using Nominatim
        normalized_address = self.normalize_address(address)
        if normalized_address:
            return normalized_address

        return address

================
File: utils/auth.py
================
# utils/auth.py
import os
from dotenv import load_dotenv
import bcrypt
import jwt
from datetime import datetime, timedelta
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AuthHandler:
    def __init__(self):
        load_dotenv()
        self.secret_key = os.getenv('JWT_SECRET_KEY')
        if not self.secret_key:
            raise ValueError("JWT_SECRET_KEY not found in environment variables")
            
        # Initialize with default admin user (case insensitive key)
        admin_email = 'Matt.Sadik@sothebys.realty'
        admin_password = "Chance72$$"
        salt = bcrypt.gensalt()
        hashed_password = bcrypt.hashpw(admin_password.encode('utf-8'), salt)
        
        self.users = {
            admin_email: {
                'password': hashed_password,
                'name': 'Matt Sadik',
                'role': 'admin',
                'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'created_by': 'system'
            }
        }
        logger.info("AuthHandler initialized with admin user")

    def verify_email_domain(self, email):
        """Verify email belongs to Sotheby's domain."""
        email = email.lower()
        valid = email.endswith(('sothebys.realty', 'sothebysrealty.com'))
        logger.info(f"Email domain verification for {email}: {'valid' if valid else 'invalid'}")
        return valid

    def add_user(self, email, password, name, added_by):
        """Add a new user to the system."""
        try:
            if not self.verify_email_domain(email):
                raise ValueError("Only Sotheby's email addresses are allowed")
            
            # Case-insensitive check for existing user
            if any(existing.lower() == email.lower() for existing in self.users.keys()):
                raise ValueError("User already exists")
            
            # Hash password
            salt = bcrypt.gensalt()
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            
            self.users[email] = {
                'password': hashed,
                'name': name,
                'role': 'user',
                'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'created_by': added_by
            }
            logger.info(f"Successfully added new user: {email}")
            return True
            
        except Exception as e:
            logger.error(f"Error adding user {email}: {str(e)}")
            raise

    def is_admin(self, email):
        """Check if user is an admin."""
        # Case-insensitive check for admin role
        matching_email = next(
            (stored_email for stored_email in self.users.keys() 
             if stored_email.lower() == email.lower()),
            None
        )
        is_admin = matching_email and self.users[matching_email].get('role') == 'admin'
        logger.info(f"Admin check for {email}: {is_admin}")
        return is_admin

    def get_all_users(self):
        """Get list of all users (excluding passwords)."""
        try:
            users = {
                email: {
                    'name': info['name'],
                    'role': info.get('role', 'user'),
                    'created_at': info.get('created_at', 'N/A'),
                    'created_by': info.get('created_by', 'N/A')
                }
                for email, info in self.users.items()
            }
            logger.info(f"Retrieved {len(users)} users")
            return users
        except Exception as e:
            logger.error(f"Error getting users: {str(e)}")
            return {}

    def login(self, email, password):
        """Authenticate user and return JWT token."""
        try:
            # Case-insensitive email check
            matching_email = next(
                (stored_email for stored_email in self.users.keys() 
                 if stored_email.lower() == email.lower()),
                None
            )
            
            if not matching_email:
                logger.warning(f"Login failed: User {email} not found")
                return None
            
            stored_password = self.users[matching_email]['password']
            if isinstance(stored_password, str):
                stored_password = stored_password.encode('utf-8')
            
            if bcrypt.checkpw(password.encode('utf-8'), stored_password):
                token = jwt.encode({
                    'email': matching_email,  # Use the correctly-cased email
                    'name': self.users[matching_email]['name'],
                    'role': self.users[matching_email].get('role', 'user'),
                    'exp': datetime.utcnow() + timedelta(days=1)
                }, self.secret_key, algorithm='HS256')
                
                logger.info(f"Login successful for user: {matching_email}")
                return token
            
            logger.warning(f"Login failed: Invalid password for {email}")
            return None
            
        except Exception as e:
            logger.error(f"Login error for {email}: {str(e)}")
            return None

    def verify_token(self, token):
        """Verify JWT token and return user info."""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            # Case-insensitive email check
            matching_email = next(
                (stored_email for stored_email in self.users.keys() 
                 if stored_email.lower() == payload['email'].lower()),
                None
            )
            
            if matching_email:
                logger.info(f"Token verified for user: {matching_email}")
                return {
                    'email': matching_email,
                    'name': self.users[matching_email]['name'],
                    'role': self.users[matching_email].get('role', 'user')
                }
            
            logger.warning("Token verification failed: User not found")
            return None
            
        except jwt.ExpiredSignatureError:
            logger.warning("Token verification failed: Token expired")
            return None
        except jwt.InvalidTokenError:
            logger.warning("Token verification failed: Invalid token")
            return None
        except Exception as e:
            logger.error(f"Token verification error: {str(e)}")
            return None

    def delete_user(self, email, admin_email):
        """Delete a user (admin only)."""
        try:
            if not self.is_admin(admin_email):
                raise ValueError("Only administrators can delete users")
                
            # Case-insensitive checks
            admin_match = next(
                (stored_email for stored_email in self.users.keys() 
                 if stored_email.lower() == admin_email.lower()),
                None
            )
            user_match = next(
                (stored_email for stored_email in self.users.keys() 
                 if stored_email.lower() == email.lower()),
                None
            )
            
            if email.lower() == admin_email.lower():
                raise ValueError("Cannot delete your own admin account")
            if not user_match:
                raise ValueError("User not found")
            
            del self.users[user_match]
            logger.info(f"User {email} successfully deleted by admin {admin_email}")
            return True
            
        except Exception as e:
            logger.error(f"Error deleting user {email}: {str(e)}")
            raise

================
File: utils/data_processor.py
================
# utils/data_processor.py
import pandas as pd
from datetime import datetime
from utils.address_standardizer import AddressStandardizer

class DataProcessor:
    def __init__(self, valid_property_classes):
        self.valid_property_classes = valid_property_classes
        self.address_standardizer = AddressStandardizer()

    def load_data(self, file_path):
        """Load the raw data from an Excel file."""
        return pd.read_excel(file_path)

    def filter_data(self, df):
        """Filter data based on specific property classes."""
        filtered_df = df[df["Property class"].isin(self.valid_property_classes)]
        return filtered_df.drop(columns=["Block & Lot"], errors="ignore")

    def standardize_addresses(self, df):
        """Concatenate address fields and standardize address."""
        df["Address"] = df["Address"].apply(self.address_standardizer.standardize)
        df["Full Address"] = df["Address"] + ", " + df["City"] + ", " + df["State"] + " " + df["Zipcode"].astype(str)
        return df

    def remove_duplicates(self, df):
        """Remove duplicate entries based on Full Address while keeping the first occurrence."""
        # Sort by date to keep the most recent entry (if date column exists)
        if 'Sale date' in df.columns:
            df['Sale date'] = pd.to_datetime(df['Sale date'], errors='coerce')
            df = df.sort_values('Sale date', ascending=False)

        # Drop duplicates based on Full Address
        deduped_df = df.drop_duplicates(subset=['Full Address'], keep='first')
        
        # Reset index after deduplication
        deduped_df = deduped_df.reset_index(drop=True)
        
        return deduped_df

    def process_file(self, file_path):
        """Process and validate the data."""
        try:
            # Load and process the data
            df = self.load_data(file_path)
            filtered_df = self.filter_data(df)
            standardized_df = self.standardize_addresses(filtered_df)
            deduped_df = self.remove_duplicates(standardized_df)
            
            # Add processing timestamp in readable format
            deduped_df["Processed Date"] = datetime.now().strftime("%B %d, %Y at %I:%M %p")
            
            return deduped_df
        except Exception as e:
            print(f"Error processing file: {str(e)}")
            return None

================
File: utils/database.py
================
# utils/database.py
import os
from pymongo import MongoClient
from datetime import datetime
import gridfs
import pandas as pd
import io

class DatabaseHandler:
    def __init__(self):
        # Get MongoDB connection string from environment variable
        mongo_uri = os.getenv('MONGODB_URI')
        if not mongo_uri:
            raise ValueError("MongoDB URI not found in environment variables")
        
        self.client = MongoClient(mongo_uri)
        self.db = self.client.sothebys_validator
        self.fs = gridfs.GridFS(self.db)
        
    def save_file(self, filename, file_data, file_type, metadata=None):
        """Save file to GridFS with metadata."""
        return self.fs.put(
            file_data,
            filename=filename,
            file_type=file_type,
            metadata=metadata,
            upload_date=datetime.now()
        )
    
    def get_file(self, file_id):
        """Retrieve file from GridFS."""
        return self.fs.get(file_id)
    
    def save_processing_log(self, log_entry):
        """Save processing log entry to MongoDB."""
        self.db.processing_logs.insert_one({
            **log_entry,
            'timestamp': datetime.now()
        })
    
    def get_processing_logs(self):
        """Retrieve all processing logs."""
        return list(self.db.processing_logs.find().sort('timestamp', -1))
    
    def save_processed_data(self, data_df, metadata):
        """Save processed pandas DataFrame to MongoDB."""
        # Convert DataFrame to CSV string
        csv_buffer = io.StringIO()
        data_df.to_csv(csv_buffer, index=False)
        
        # Save to GridFS
        file_id = self.fs.put(
            csv_buffer.getvalue().encode('utf-8'),
            filename=f"processed_{metadata['timestamp']}.csv",
            metadata=metadata
        )
        return file_id
    
    def get_processed_data(self, file_id):
        """Retrieve processed data as DataFrame."""
        file_data = self.fs.get(file_id)
        csv_data = io.StringIO(file_data.read().decode('utf-8'))
        return pd.read_csv(csv_data)
